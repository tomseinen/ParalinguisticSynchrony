{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pickle\r\n",
    "import glob, os\r\n",
    "import time\r\n",
    "import copy\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "#scikitlearn\r\n",
    "from sklearn.manifold import TSNE\r\n",
    "from sklearn.cluster import AgglomerativeClustering\r\n",
    "from scipy.cluster.hierarchy import dendrogram\r\n",
    "from sklearn.semi_supervised import LabelSpreading\r\n",
    "#Pyannote\r\n",
    "from pyannote.core import Segment, notebook, Timeline\r\n",
    "from pyannote.audio.utils.signal import Binarize, Peak\r\n",
    "#Pydub\r\n",
    "from pydub import AudioSegment\r\n",
    "from pydub.playback import play\r\n",
    "#Praat\r\n",
    "import parselmouth"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "location=\"/location/to/extracted/pyannote/and/audio/files/\"\r\n",
    "patientIdList=[\"[ID of patient]\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from pyannote.core import SlidingWindowFeature\r\n",
    "plot_ready = lambda scores: SlidingWindowFeature(np.exp(scores.data[:, 1:]), scores.sliding_window)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# function to cluster the audio segments within a session audio file and output the result.\r\n",
    "def ClusterAudio (patientIdLocation,wavfile):\r\n",
    "    ## Load the scores\r\n",
    "    print(\"Loading scores\")\r\n",
    "    sessionName=wavfile.replace('.wav', '')\r\n",
    "    sad_scores = pickle.load( open( sessionName+\"_sad.p\", \"rb\" ) )\r\n",
    "    scd_scores = pickle.load( open( sessionName+\"_scd.p\", \"rb\" ) )\r\n",
    "    ovl_scores = pickle.load( open( sessionName+\"_ovl.p\", \"rb\" ) )\r\n",
    "    embeddings = pickle.load( open( sessionName+\"_emb.p\", \"rb\" ) )\r\n",
    "    \r\n",
    "    ## speech regions\r\n",
    "    binarize = Binarize(offset=0.52, onset=0.52, log_scale=True,min_duration_off=0.1, min_duration_on=0.1)\r\n",
    "    speech = binarize.apply(sad_scores, dimension=1)\r\n",
    "    ## speaker change point\r\n",
    "    peak = Peak(alpha=0.10, min_duration=0.10, log_scale=True)\r\n",
    "    partition = peak.apply(scd_scores, dimension=1)\r\n",
    "    ## speech turns are simply the intersection of SAD and SCD\r\n",
    "    speech_turns = partition.crop(speech)\r\n",
    "    ## only keep long speech turns\r\n",
    "    alpha=0.5 #0.5 DEFAULT\r\n",
    "    long_turns = Timeline(segments=[s for s in speech_turns if s.duration > alpha])\r\n",
    "    print(str(long_turns.__len__())+\" long turns\")\r\n",
    "    \r\n",
    "    ## Get sound with praat to calculate left right intensity\r\n",
    "    snd = parselmouth.Sound(patientIdLocation+\"/\"+wavfile)\r\n",
    "    if snd.get_number_of_channels==2:\r\n",
    "        Int_left=snd.extract_left_channel().to_intensity()\r\n",
    "        Int_left_ar=Int_left.as_array()[0]\r\n",
    "        Int_right=snd.extract_right_channel().to_intensity()\r\n",
    "        Int_right_ar=Int_right.as_array()[0]\r\n",
    "        Int_LR=Int_left_ar-Int_right_ar\r\n",
    "    else :\r\n",
    "        Int_LR=snd.to_intensity()\r\n",
    "    \r\n",
    "    ## Get features for speech turns\r\n",
    "    print(\"building features\")\r\n",
    "    Xemb,Xovl,Xlr,Xa,keep = [],[],[],[],[]\r\n",
    "    for segment in long_turns:\r\n",
    "        xemb = embeddings.crop(segment)#, mode='strict')\r\n",
    "        xovl = plot_ready(ovl_scores).crop(segment)\r\n",
    "        # average speech turn embedding if not empty\r\n",
    "        if len(xemb) > 0:\r\n",
    "            keep.append(1)\r\n",
    "            ## embedding\r\n",
    "            meanx=np.mean(xemb, axis=0)\r\n",
    "            ## overlap\r\n",
    "            meanxovl=np.mean(xovl,axis=0)\r\n",
    "            ## Left Right Intensity\r\n",
    "            fromframe_LR=np.rint(Int_left.get_frame_number_from_time(segment.start)).astype(int)\r\n",
    "            toframe_LR=np.rint(Int_left.get_frame_number_from_time(segment.end)).astype(int)\r\n",
    "            if fromframe_LR==toframe_LR:\r\n",
    "                meanlr=Int_LR[fromframe_LR]\r\n",
    "            else:\r\n",
    "                meanlr=np.mean(Int_LR[fromframe_LR:toframe_LR],axis=0)\r\n",
    "            if np.isnan(meanlr):\r\n",
    "                meanlr=0\r\n",
    "            Xa.append(np.concatenate([meanx,meanxovl,[meanlr]])) #DEFAULT\r\n",
    "        else :\r\n",
    "            keep.append(0)\r\n",
    "    \r\n",
    "    Xa = np.vstack(Xa)\r\n",
    "    \r\n",
    "    ## Cluster the result\r\n",
    "    print(\"clustering result\")\r\n",
    "    clusterModel = AgglomerativeClustering(affinity='euclidean',n_clusters=4,linkage='ward')\r\n",
    "    Y=clusterModel.fit_predict(Xa)\r\n",
    "    \r\n",
    "    ## plot the clusters\r\n",
    "    print(\"export cluster plot\")\r\n",
    "    OutputClusterPlot(Xa,Y,sessionName)\r\n",
    "    \r\n",
    "    ## Export cluster sound\r\n",
    "    print(\"export cluster audio files\")\r\n",
    "    OutputClusterAudio(patientIdLocation,wavfile,sessionName,long_turns,Y,keep)\r\n",
    "    \r\n",
    "    ## create result matrix\r\n",
    "    print(\"create result matrix\")\r\n",
    "    clusterTimes = np.array([[0.00 for x in range(3)] for y in range(len(long_turns))])\r\n",
    "    countY=0\r\n",
    "    for segment in long_turns:\r\n",
    "        clusterTimes[countY][0]=segment.start\r\n",
    "        clusterTimes[countY][1]=segment.end\r\n",
    "        clusterTimes[countY][2]=Y[countY]\r\n",
    "        countY=countY+1\r\n",
    "    \r\n",
    "    ## Put clusters on pitch\r\n",
    "    print(\"clusters to pitch\")\r\n",
    "    pitch = snd.to_pitch()\r\n",
    "    pitchLength=len(pitch)\r\n",
    "    t1=pitch.t1\r\n",
    "    dt=pitch.dt\r\n",
    "    clusterPitch = np.array([[-1.0 for x in range(3)] for y in range(pitchLength)])\r\n",
    "    row=0\r\n",
    "    t=t1\r\n",
    "    for frame in pitch:\r\n",
    "        clusterPitch[row][0]=t\r\n",
    "        clusterPitch[row][1]=frame.as_array()[0][0]\r\n",
    "        clust=clusterTimes[(clusterTimes[:,0] < t)&(clusterTimes[:,1] > t)]\r\n",
    "        if len(clust)==1:\r\n",
    "            clusterPitch[row][2]=clust[0,2]\r\n",
    "        elif len(clust)>1:\r\n",
    "            print(\"ERROR more than 2 segments in timeframe\")\r\n",
    "        else:\r\n",
    "            clusterPitch[row][2]=-1\r\n",
    "        row=row+1\r\n",
    "        t=t+dt\r\n",
    "    \r\n",
    "    ## Export the result\r\n",
    "    print(\"Exporting result\")\r\n",
    "    clusterPitch = pd.DataFrame(clusterPitch)\r\n",
    "    clusterPitch.columns = ['t', 'p', 'cluster']\r\n",
    "    clusterPitch.to_csv(sessionName+\"_result.csv\", index = False, header=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Function for writing cluster output to 4 audio files\r\n",
    "def OutputClusterAudio(patientIdLocation,wavfile,sessionName,long_turns,Y,keep):\r\n",
    "    fullSesWav = AudioSegment.from_wav(patientIdLocation+\"/\"+wavfile)\r\n",
    "    audioFill0=fullSesWav[0:100]\r\n",
    "    audioFill1=fullSesWav[0:100]\r\n",
    "    audioFill2=fullSesWav[0:100]\r\n",
    "    audioFill3=fullSesWav[0:100]\r\n",
    "    countY=0\r\n",
    "    for segmentnr in range(len(long_turns)):\r\n",
    "        #print(segmentnr)\r\n",
    "        if keep[segmentnr]==1:\r\n",
    "            begin=long_turns.segments_list_[segmentnr].start*1000\r\n",
    "            end=long_turns.segments_list_[segmentnr].end*1000\r\n",
    "            audioseg=fullSesWav[begin:end]\r\n",
    "            if Y[segmentnr-countY]==0:\r\n",
    "                audioFill0=audioFill0+audioseg\r\n",
    "            elif Y[segmentnr-countY]==1:\r\n",
    "                audioFill1=audioFill1+audioseg\r\n",
    "            elif Y[segmentnr-countY]==2:\r\n",
    "                audioFill2=audioFill2+audioseg\r\n",
    "            elif Y[segmentnr-countY]==3:\r\n",
    "                audioFill3=audioFill3+audioseg\r\n",
    "        else: \r\n",
    "            countY=countY+1\r\n",
    "    print(\"0:\"+str(audioFill0.duration_seconds/60))\r\n",
    "    print(\"1:\"+str(audioFill1.duration_seconds/60))\r\n",
    "    print(\"2:\"+str(audioFill2.duration_seconds/60))\r\n",
    "    print(\"3:\"+str(audioFill3.duration_seconds/60))\r\n",
    "    audioFill0.export(sessionName+\"_0.mp3\", format=\"mp3\")\r\n",
    "    audioFill1.export(sessionName+\"_1.mp3\", format=\"mp3\")\r\n",
    "    audioFill2.export(sessionName+\"_2.mp3\", format=\"mp3\")\r\n",
    "    audioFill3.export(sessionName+\"_3.mp3\", format=\"mp3\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Function for creating a TSNE plot of the data that is used for clustering. Use plot to visualy inspect the diarization.\r\n",
    "def OutputClusterPlot(Xa,Y,sessionName):\r\n",
    "    tsne = TSNE(n_components=2, metric=\"euclidean\", perplexity=30, random_state=42)\r\n",
    "    X_2d = tsne.fit_transform(Xa)\r\n",
    "    fig, ax = plt.subplots()\r\n",
    "    fig.set_figheight(5)\r\n",
    "    fig.set_figwidth(5)\r\n",
    "    scatter=ax.scatter(*X_2d.T, c=Y)\r\n",
    "    legend1 = ax.legend(*scatter.legend_elements(),\r\n",
    "                        loc=\"lower left\", title=\"Classes\")\r\n",
    "    ax.add_artist(legend1)\r\n",
    "    plt.savefig(sessionName+\"_plot.png\",)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Run for multiple patients\r\n",
    "for patientId in patientIdList:\r\n",
    "    patientIdLocation=location+patientId\r\n",
    "    os.chdir(patientIdLocation)\r\n",
    "    for wavfile in glob.glob(\"*.wav\"):\r\n",
    "        print(wavfile)\r\n",
    "        ClusterAudio(patientIdLocation,wavfile)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyannote",
   "language": "python",
   "name": "pyannote"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}