{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import pickle\r\n",
    "import glob, os\r\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the pynannote-audio models\r\n",
    "sad = torch.hub.load('pyannote/pyannote-audio', 'sad_ami',batch_size=18)\r\n",
    "scd = torch.hub.load('pyannote/pyannote-audio', 'scd_ami',batch_size=18)\r\n",
    "ovl = torch.hub.load('pyannote/pyannote-audio', 'ovl_ami',batch_size=18)\r\n",
    "emb = torch.hub.load('pyannote/pyannote-audio', 'emb_ami',batch_size=18)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "location=\"/location/to/audio/files/\"\r\n",
    "patientIdList=[\"[ID of patient]\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Function to extract the pynannote-audio output and embeddings\r\n",
    "def pyannoteExtract(wavefile,sessionName, patientId):\r\n",
    "    audiofile = {'uri': 'filename', 'audio': wavefile}\r\n",
    "    \r\n",
    "    T0 = time.time()\r\n",
    "    #print(wavefile)\r\n",
    "    sad_scores = sad(audiofile)\r\n",
    "    pickle.dump(sad_scores, open( sessionName+\"_sad.p\", \"wb\" ) )\r\n",
    "    T1 = time.time()\r\n",
    "    print(f'Time sad: {T1 - T0}')\r\n",
    "    \r\n",
    "    scd_scores = scd(audiofile)\r\n",
    "    pickle.dump(scd_scores, open( sessionName+\"_scd.p\", \"wb\" ) )\r\n",
    "    T2 = time.time()\r\n",
    "    print(f'Time scd: {T2 - T1}')\r\n",
    "    \r\n",
    "    ovl_scores = ovl(audiofile)\r\n",
    "    pickle.dump(ovl_scores, open( sessionName+\"_ovl.p\", \"wb\" ) )\r\n",
    "    T3 = time.time()\r\n",
    "    print(f'Time ovl: {T3 - T2}')\r\n",
    "    \r\n",
    "    embeddings = emb(audiofile)\r\n",
    "    pickle.dump(embeddings, open( sessionName+\"_emb.p\", \"wb\" ) )\r\n",
    "    T4 = time.time()\r\n",
    "    print(f'Time emb: {T4 - T3}')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run the extraction function for all patients and session audio files\r\n",
    "for patientId in patientIdList:\r\n",
    "    patientIdLocation=location+patientId\r\n",
    "    os.chdir(patientIdLocation)\r\n",
    "    for wavfile in glob.glob(\"*.wav\"):\r\n",
    "        print(wavfile)\r\n",
    "        sessionName=wavfile.replace('.wav', '')\r\n",
    "        T0 = time.time()\r\n",
    "        fileLocation=patientIdLocation+\"/\"+wavfile\r\n",
    "        pyannoteExtract(fileLocation,sessionName,patientId)      \r\n",
    "        print(time.time() - T0)\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyannote",
   "language": "python",
   "name": "pyannote"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}